# Resource Quotas for GPU Workloads
#
# Limit GPU usage per namespace to prevent runaway costs.

apiVersion: v1
kind: ResourceQuota
metadata:
  name: inference-quota
  namespace: inference
spec:
  hard:
    requests.nvidia.com/gpu: "20"
    limits.nvidia.com/gpu: "20"
    requests.cpu: "100"
    requests.memory: 400Gi
    limits.cpu: "200"
    limits.memory: 800Gi
    pods: "50"
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: training-quota
  namespace: training
spec:
  hard:
    requests.nvidia.com/gpu: "32"
    limits.nvidia.com/gpu: "32"
    requests.cpu: "256"
    requests.memory: 1Ti
    limits.cpu: "512"
    limits.memory: 2Ti
    pods: "100"
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: development-quota
  namespace: development
spec:
  hard:
    requests.nvidia.com/gpu: "4"
    limits.nvidia.com/gpu: "4"
    requests.cpu: "16"
    requests.memory: 64Gi
    limits.cpu: "32"
    limits.memory: 128Gi
    pods: "20"
---
# Limit Range - set defaults for pods without explicit requests
apiVersion: v1
kind: LimitRange
metadata:
  name: gpu-limit-range
  namespace: inference
spec:
  limits:
    - type: Container
      default:
        cpu: "2"
        memory: 8Gi
      defaultRequest:
        cpu: "1"
        memory: 4Gi
    - type: PersistentVolumeClaim
      max:
        storage: 500Gi
      min:
        storage: 1Gi
