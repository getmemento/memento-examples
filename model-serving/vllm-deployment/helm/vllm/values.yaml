# vLLM Helm Chart Values

replicaCount: 2

image:
  repository: vllm/vllm-openai
  tag: "v0.4.0"
  pullPolicy: IfNotPresent

# Model configuration
model:
  name: "mistralai/Mistral-7B-Instruct-v0.2"
  maxModelLen: 8192
  gpuMemoryUtilization: 0.9
  tensorParallelSize: 1
  quantization: ""  # Options: awq, gptq, squeezellm, or empty for none
  enablePrefixCaching: true

# HuggingFace token for gated models
huggingfaceToken:
  # Set to true to use existing secret
  existingSecret: ""
  secretKey: "token"

# Resource configuration
resources:
  requests:
    cpu: "4"
    memory: "16Gi"
    nvidia.com/gpu: 1
  limits:
    cpu: "8"
    memory: "32Gi"
    nvidia.com/gpu: 1

# GPU scheduling
gpu:
  enabled: true
  tolerations:
    - key: nvidia.com/gpu
      operator: Equal
      value: "true"
      effect: NoSchedule
  nodeSelector: {}
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: nvidia.com/gpu
                operator: In
                values:
                  - "true"

# Pod anti-affinity for HA
podAntiAffinity:
  enabled: true
  topologyKey: kubernetes.io/hostname

# Service configuration
service:
  type: ClusterIP
  port: 8000
  annotations: {}

# External LoadBalancer (optional)
externalService:
  enabled: false
  type: LoadBalancer
  port: 80
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internal"

# Autoscaling
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70

# KEDA autoscaling (preferred over HPA)
keda:
  enabled: false
  pollingInterval: 15
  cooldownPeriod: 300
  prometheusServerAddress: "http://prometheus-server.monitoring.svc.cluster.local:9090"
  triggers:
    pendingRequests:
      threshold: 10
      activationThreshold: 5
    runningRequests:
      threshold: 20
      activationThreshold: 10

# Prometheus monitoring
monitoring:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 15s
  alerts:
    enabled: true

# Pod disruption budget
pdb:
  enabled: true
  minAvailable: 1

# Probes
probes:
  readiness:
    initialDelaySeconds: 120
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 30
  liveness:
    initialDelaySeconds: 300
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3

# Graceful shutdown
terminationGracePeriodSeconds: 300
preStopSleepSeconds: 30

# Storage
storage:
  cache:
    enabled: true
    size: 50Gi
  sharedMemory:
    enabled: true
    size: 8Gi
